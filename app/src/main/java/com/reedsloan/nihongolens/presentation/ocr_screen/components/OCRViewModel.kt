package com.reedsloan.nihongolens.presentation.ocr_screen.components

import android.app.Application
import android.graphics.Bitmap
import android.graphics.Matrix
import android.graphics.Point
import android.util.Log
import androidx.camera.core.ImageCapture.OnImageCapturedCallback
import androidx.camera.core.ImageCaptureException
import androidx.camera.core.ImageProxy
import androidx.core.content.ContextCompat
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.atilika.kuromoji.ipadic.Token
import com.atilika.kuromoji.ipadic.Tokenizer
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.japanese.JapaneseTextRecognizerOptions
import com.reedsloan.nihongolens.domain.model.JapaneseEnglishDictionary
import com.reedsloan.nihongolens.domain.model.JapaneseEnglishEntry
import com.reedsloan.nihongolens.domain.use_case.GetDictionary
import dagger.hilt.android.lifecycle.HiltViewModel
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.update
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import javax.inject.Inject


@HiltViewModel
class OCRViewModel @Inject constructor(
    private val app: Application,
    private val getDictionary: GetDictionary,
) : ViewModel() {
    private val _state = MutableStateFlow(OCRScreenState())
    val state = _state
    private lateinit var dictionary: JapaneseEnglishDictionary
    private val dictionaryJob = viewModelScope.launch {
        _state.update { it.copy(dictionaryIsLoading = true) }
        withContext(Dispatchers.IO) {
            dictionary = getDictionary()
        }.let {
            _state.update { it.copy(dictionaryIsLoading = false) }
        }
    }
    private val recognizer = TextRecognition.getClient(
        JapaneseTextRecognizerOptions.Builder().build()
    )

    private lateinit var tokenizer: Tokenizer

    private val tokenizerJob = viewModelScope.launch {
        _state.update { it.copy(tokenizerLoading = true) }

        // This withContext block is a coroutine context switcher, it switches to the IO dispatcher
        withContext(Dispatchers.IO) {
            tokenizer = Tokenizer()
        }.let {
            _state.update { it.copy(tokenizerLoading = false) }
        }
    }

    init {
        tokenizerJob.start()
        dictionaryJob.start()
    }

    fun onEvent(event: OCREvent) {
        when (event) {
            is OCREvent.ClickCamera -> {
                _state.update { it.copy(ocrViewMode = OCRViewMode.Result, isScanning = true) }
                event.localCameraController.takePicture(ContextCompat.getMainExecutor(app),
                    object : OnImageCapturedCallback() {
                        override fun onCaptureSuccess(image: ImageProxy) {
                            super.onCaptureSuccess(image)

                            // Generate a matrix to rotate the image based on the image's rotation
                            val matrix = Matrix().apply {
                                postRotate(image.imageInfo.rotationDegrees.toFloat())
                            }

                            val rotatedBitmap = Bitmap.createBitmap(
                                image.toBitmap(), 0, 0, image.width, image.height, matrix, true
                            )
                            image.close()

                            runTextRecognition(rotatedBitmap)

                            // We must call this so the UI can display the image
                            updatePreviewPhoto(rotatedBitmap)

                        }

                        override fun onError(exception: ImageCaptureException) {
                            super.onError(exception)
                            Log.e("OCRViewModel", "Could not take photo", exception)
                            // update the state with the error message
                            _state.update { it.copy(imageCaptureError = exception.message) }
                        }
                    })
            }

            is OCREvent.ScanImage -> {
                _state.update { it.copy(isScanning = true, ocrViewMode = OCRViewMode.Result) }

                runTextRecognition(event.image)

                // We must call this so the UI can display the image
                updatePreviewPhoto(event.image)
            }

            is OCREvent.StopScan -> {
                _state.update { it.copy(isScanning = false) }
            }

            is OCREvent.OnClickLine -> {
                _state.update {
                    it.copy(
                        ocrViewMode = OCRViewMode.InspectResult(event.lineId)
                    )
                }
                applyTokenizedAndDefinitionResultsForText(event.text, event.lineId)
            }

            is OCREvent.OnClickTextBlock -> {

            }

            is OCREvent.OnClickWord -> {

            }

            is OCREvent.OnBack -> {
                when (state.value.ocrViewMode) {
                    OCRViewMode.Result -> {
                        _state.update { it.copy(ocrViewMode = OCRViewMode.Camera) }
                        // Clear the image and results
                        _state.update { it.copy(image = null, ocrResults = null) }
                    }

                    is OCRViewMode.InspectResult -> {
                        _state.update { it.copy(ocrViewMode = OCRViewMode.Result) }
                    }

                    OCRViewMode.Camera -> {
                        event.navigateBack()
                    }
                }
            }
        }
    }

    private suspend fun getJapaneseEnglishEntries(tokens: List<Token>): Map<Token, List<JapaneseEnglishEntry>> {
        dictionaryJob.join()


        return tokens.associateWith { token ->
            val results = emptyList<JapaneseEnglishEntry>().toMutableList()
            // Add all entries that match the string at the beginning so they are shown first
            dictionary.entries.forEach { entry ->
                if (entry.word.any { it.text == token.baseForm }) {
                    results.add(entry)
                } else if (entry.word.any { it.text == token.surface }) {
                    results.add(entry)
                }
            }

            // If no entries are found for the word, search for kana-only words as well
            if (results.isEmpty()) {
                // also search the kana only words
                dictionary.entries.forEach { entry ->
                    if (entry.wordKanaOnly.any { it.text == token.baseForm }) {
                        results.add(entry)
                    } else if (entry.wordKanaOnly.any { it.text == token.surface }) {
                        results.add(entry)
                    }
                }
            }
            results
        }
    }

    private fun updatePreviewPhoto(image: Bitmap) {
        _state.update { it.copy(image = image) }
    }

    /**
     * Tokenizes the text and gets the definitions for each token and updates the state with the results.
     */
    private fun applyTokenizedAndDefinitionResultsForText(string: String, lineId: Int) {
        viewModelScope.launch {
            withContext(Dispatchers.IO) {
                // Process after the OCR results are updated so we can update the tokenized text
                val tokenizedText = tokenizeText(string)
                val tokenToDefinitionMap = getJapaneseEnglishEntries(tokenizedText.map { it })

                _state.update { ocrState ->
                    ocrState.copy(
                        ocrResults = ocrState.ocrResults?.map { ocrResult ->
                            ocrResult.copy(
                                tokenizedText = tokenizedText,
                                tokenToDefinitionMap = ocrResult.tokenToDefinitionMap + tokenToDefinitionMap
                            )
                        }
                    )
                }
            }
        }
    }


    private fun runTextRecognition(bitmap: Bitmap) {
        val image = InputImage.fromBitmap(bitmap, 0)

        recognizer.process(image).addOnSuccessListener { texts ->
            viewModelScope.launch {
                _state.update { ocrState ->
                    ocrState.copy(
                        isScanning = false,
                        ocrResults =
                        texts.textBlocks.mapIndexed { index, block ->
                            val topLeft =block.lines.first().cornerPoints?.get(0)
                                ?.let { Point(it.x, it.y) }!!
                            val bottomRight = block.lines.last().cornerPoints?.get(2)
                                ?.let { Point(it.x, it.y) }!!

                            val isVertical = topLeft.x > bottomRight.x

                            OCRResult(
                                text = block.text,
                                topLeft = topLeft,
                                bottomRight = bottomRight,
                                confidence = block.lines.first().confidence,
                                tokenizedText = emptyList(),
                                angle = block.lines.first().angle,
                                id = index,
                                tokenToDefinitionMap = emptyMap(),
                                isVertical = isVertical
                            )
                        }
                    )
                }
            }
        }.addOnFailureListener { e -> // Task failed with an exception
            _state.update { it.copy(isScanning = false, error = e.message) }
            e.printStackTrace()
        }
    }

    private suspend fun tokenizeText(text: String): List<Token> {
        // this is necessary to ensure the tokenizer is loaded before we tokenize the text
        tokenizerJob.join()

        return tokenizer.tokenize(text)
    }

}